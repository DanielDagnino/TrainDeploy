{
    "encoder_layers": 12,
    "encoder_embed_dim": 768,
    "encoder_ffn_embed_dim": 3072,
    "encoder_attention_heads": 12,
    "activation_fn": "gelu",
    "dropout": 0.0,
    "attention_dropout": 0.0,
    "activation_dropout": 0.0,
    "encoder_layerdrop": 0.05,
    "dropout_input": 0.0,
    "layer_norm_first": false,
    "conv_bias": false,
    "conv_pos": 128,
    "conv_pos_groups": 16,
    "relative_position_embedding": true,
    "num_buckets": 320,
    "max_distance": 800,
    "gru_rel_pos": true,
    "deep_norm": true,
    "input_patch_size": 16,
    "layer_wise_gradient_decay_ratio": 0.6,
    "embed_dim": 512,
    "finetuned_model": false
}